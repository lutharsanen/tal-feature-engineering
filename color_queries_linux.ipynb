{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "known-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import matplotlib.colors as mc\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "innocent-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import argparse\n",
    "import sys\n",
    "import webcolors\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "COLORS = (\n",
    "    (255,255,255),\n",
    "    (255,0,0),\n",
    "    (0,255,0),\n",
    "    (0,0,255),\n",
    "    (255,255,0),\n",
    "    (0,255,255),\n",
    "    (255,0,255),\n",
    "    (192,192,192),\n",
    "    (128,128,128),\n",
    "    (128,0,0),\n",
    "    (128,128,0),\n",
    "    (0,128,0),\n",
    "    (128,0,128),\n",
    "    (0,128,128),\n",
    "    (0,0,128)\n",
    ")\n",
    "\n",
    "def closest_color(rgb):\n",
    "    r, g, b = rgb\n",
    "    color_diffs = []\n",
    "    for color in COLORS:\n",
    "        cr, cg, cb = color\n",
    "        color_diff = sqrt(abs(r - cr)**2 + abs(g - cg)**2 + abs(b - cb)**2)\n",
    "        color_diffs.append((color_diff, color))\n",
    "    return min(color_diffs)[1]\n",
    "\n",
    "def get_colors(image_file, numcolors=10, resize=150):\n",
    "    # Resize image to speed up processing\n",
    "    img = Image.open(image_file)\n",
    "    img = img.copy()\n",
    "    img.thumbnail((resize, resize))\n",
    "\n",
    "    # Reduce to palette\n",
    "    paletted = img.convert('P', palette=Image.ADAPTIVE, colors=numcolors)\n",
    "\n",
    "    # Find dominant colors\n",
    "    palette = paletted.getpalette()\n",
    "    color_counts = sorted(paletted.getcolors(), reverse=True)\n",
    "    colors = list()\n",
    "    for i in range(numcolors):\n",
    "        palette_index = color_counts[i][1]\n",
    "        dominant_color = palette[palette_index*3:palette_index*3+3]\n",
    "        colors.append(tuple(dominant_color))\n",
    "\n",
    "    return colors\n",
    "\n",
    "def get_mask_image(mask, box):\n",
    "    mask_h = int(math.ceil(box[3] - box[1]))\n",
    "    mask_w = int(math.ceil(box[2] - box[0]))\n",
    "\n",
    "    original_img = np.array(Image.fromarray(cv2.imread(\"/home/lkunam/Downloads/test.jpg\")))\n",
    "\n",
    "    temp_mask = np.zeros((mask_h, mask_w))\n",
    "\n",
    "    for h_idx in range(int(box[1]), int(box[3])):\n",
    "        for w_idx in range(int(box[0]), int(box[2])):\n",
    "            temp_mask[h_idx - int(box[1])][w_idx - int(box[0])] = mask[h_idx][w_idx]\n",
    "\n",
    "    temp_masks_ints = temp_mask.astype(int)\n",
    "\n",
    "    temp_mask_fill = np.zeros((mask_h, mask_w, 4))\n",
    "    for h_idx, h_bw in enumerate(temp_masks_ints):\n",
    "        for w_idx, w_bw in enumerate(h_bw):\n",
    "            if (w_bw == 0):\n",
    "                temp_mask_fill[h_idx][w_idx] = [0,0,0,0]\n",
    "            else:\n",
    "                orig_w = int(math.ceil(w_idx + box[0]))\n",
    "                orig_h = int(math.ceil(w_idx + box[1]))\n",
    "                temp_mask_fill[h_idx][w_idx] = np.append(original_img[orig_h][orig_w],1)\n",
    "\n",
    "    return temp_mask_fill\n",
    "\n",
    "#cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "straight-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 107, 103)\n",
      "(99, 23, 153)\n"
     ]
    }
   ],
   "source": [
    "image = \"/home/lkunam/Downloads/test.jpg\"\n",
    "new_color = get_colors(image,1)\n",
    "print(new_color[0])\n",
    "named_color = closest_color(new_color[0])\n",
    "print(named_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sixth-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_from_masks(image):\n",
    "    detectron2_img = cv2.imread(image)\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    outputs = predictor(detectron2_img)\n",
    "\n",
    "    masks = outputs[\"instances\"].pred_masks.cpu().numpy()\n",
    "    boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    \n",
    "    masks_arr = []\n",
    "    \n",
    "    for index, mask in enumerate(masks):\n",
    "        masks_arr.append(get_mask_image(mask, boxes[index], detectron2_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "liberal-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectron2_img = cv2.imread(\"/home/lkunam/Downloads/test.jpg\")\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(detectron2_img)\n",
    "mask = outputs[\"instances\"].pred_masks.cpu().numpy()[0]\n",
    "box = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()[0]\n",
    "\n",
    "mask_h = int(math.ceil(box[3] - box[1]))\n",
    "mask_w = int(math.ceil(box[2] - box[0]))\n",
    "\n",
    "original_img = np.array(Image.fromarray(cv2.imread(\"/home/lkunam/Downloads/test.jpg\")))\n",
    "\n",
    "temp_mask = np.zeros((mask_h, mask_w))\n",
    "\n",
    "for h_idx in range(int(box[1]), int(box[3])):\n",
    "    for w_idx in range(int(box[0]), int(box[2])):\n",
    "        temp_mask[h_idx - int(box[1])][w_idx - int(box[0])] = mask[h_idx][w_idx]\n",
    "\n",
    "temp_masks_ints = temp_mask.astype(int)\n",
    "\n",
    "temp_mask_fill = np.zeros((mask_h, mask_w, 4))\n",
    "for h_idx, h_bw in enumerate(temp_masks_ints):\n",
    "    for w_idx, w_bw in enumerate(h_bw):\n",
    "        if (w_bw == 0):\n",
    "            temp_mask_fill[h_idx][w_idx] = [0,0,0,0]\n",
    "        else:\n",
    "            orig_w = int(math.ceil(w_idx + box[0]))\n",
    "            orig_h = int(math.ceil(w_idx + box[1]))\n",
    "            temp_mask_fill[h_idx][w_idx] = np.append(original_img[orig_h][orig_w],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "passing-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test_image.png\",temp_mask_fill[:,:,0:3])\n",
    "random = Image.open(\"test_image.png\")\n",
    "new_color = get_colors(\"test_image.png\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "automatic-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = get_colors(\"test_image.png\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "peaceful-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_color(new_color[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sudden-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color\n",
    "os.remove(\"test_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "herbal-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_mask_image(masks, boxes, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-ticket",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_mask_fill' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc5105c1b9dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_mask_fill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_mask_fill' is not defined"
     ]
    }
   ],
   "source": [
    "temp_mask_fill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
